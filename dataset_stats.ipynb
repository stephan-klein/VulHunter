{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54cc5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_FILES = [\"Dataset1/Labels/dataset_1_vul_two_one_names_labels.json\", \"Dataset1/Labels/dataset_1_vul_five_one_names_labels.json\", \"Dataset2/Labels/dataset2_train_test_names_labels.json\"]\n",
    "FILTER_CATEGORIES = [\"Reentrancy\", \"reentrancy-eth\"]\n",
    "SUM_INDEXES = [[0,2],[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd2ab60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analysis for Dataset1/Labels/dataset_1_vul_two_one_names_labels.json ===\n",
      "reentrancy-eth:\n",
      "  Train names: 1018\n",
      "  Train labels - 0s: 678, 1s: 340\n",
      "  Test names: 255\n",
      "  Test labels - 0s: 170, 1s: 85\n",
      "  Total samples: 1273\n",
      "\n",
      "Summary table:\n",
      "                test_labels_0  test_labels_1  test_names  total_samples  \\\n",
      "reentrancy-eth            170             85         255           1273   \n",
      "\n",
      "                train_labels_0  train_labels_1  train_names  \n",
      "reentrancy-eth             678             340         1018  \n",
      "\n",
      "Overall totals across filtered categories:\n",
      "Total train samples: 1018\n",
      "Total test samples: 255\n",
      "Total train labels - 0s: 678, 1s: 340\n",
      "Total test labels - 0s: 170, 1s: 85\n",
      "Grand total samples: 1273\n",
      "\n",
      "=== Analysis for Dataset1/Labels/dataset_1_vul_five_one_names_labels.json ===\n",
      "reentrancy-eth:\n",
      "  Train names: 2039\n",
      "  Train labels - 0s: 1699, 1s: 340\n",
      "  Test names: 509\n",
      "  Test labels - 0s: 424, 1s: 85\n",
      "  Total samples: 2548\n",
      "\n",
      "Summary table:\n",
      "                test_labels_0  test_labels_1  test_names  total_samples  \\\n",
      "reentrancy-eth            424             85         509           2548   \n",
      "\n",
      "                train_labels_0  train_labels_1  train_names  \n",
      "reentrancy-eth            1699             340         2039  \n",
      "\n",
      "Overall totals across filtered categories:\n",
      "Total train samples: 2039\n",
      "Total test samples: 509\n",
      "Total train labels - 0s: 1699, 1s: 340\n",
      "Total test labels - 0s: 424, 1s: 85\n",
      "Grand total samples: 2548\n",
      "\n",
      "=== Analysis for Dataset2/Labels/dataset2_train_test_names_labels.json ===\n",
      "Reentrancy:\n",
      "  Train names: 28\n",
      "  Train labels - 0s: 19, 1s: 9\n",
      "  Test names: 35\n",
      "  Test labels - 0s: 23, 1s: 12\n",
      "  Total samples: 63\n",
      "\n",
      "Summary table:\n",
      "            test_labels_0  test_labels_1  test_names  total_samples  \\\n",
      "Reentrancy             23             12          35             63   \n",
      "\n",
      "            train_labels_0  train_labels_1  train_names  \n",
      "Reentrancy              19               9           28  \n",
      "\n",
      "Overall totals across filtered categories:\n",
      "Total train samples: 28\n",
      "Total test samples: 35\n",
      "Total train labels - 0s: 19, 1s: 9\n",
      "Total test labels - 0s: 23, 1s: 12\n",
      "Grand total samples: 63\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_dataset_file(file_path):\n",
    "    \"\"\"Analyze a single JSON file and return statistics for filtered categories\"\"\"\n",
    "    print(f\"\\n=== Analysis for {file_path} ===\")\n",
    "    \n",
    "    if not Path(file_path).exists():\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    # Filter data by FILTER_CATEGORIES\n",
    "    filtered_data = {k: v for k, v in data.items() if k in FILTER_CATEGORIES}\n",
    "    \n",
    "    if not filtered_data:\n",
    "        print(f\"No matching categories found. Available categories: {list(data.keys())}\")\n",
    "        return\n",
    "    \n",
    "    for category, category_data in filtered_data.items():\n",
    "        train_names = category_data.get('train_names', [])\n",
    "        test_names = category_data.get('test_names', [])\n",
    "        train_labels = category_data.get('train_labels', [])\n",
    "        test_labels = category_data.get('test_labels', [])\n",
    "        \n",
    "        # Count label distributions\n",
    "        train_labels_0 = train_labels.count(0) if train_labels else 0\n",
    "        train_labels_1 = train_labels.count(1) if train_labels else 0\n",
    "        test_labels_0 = test_labels.count(0) if test_labels else 0\n",
    "        test_labels_1 = test_labels.count(1) if test_labels else 0\n",
    "        \n",
    "        stats[category] = {\n",
    "            'train_names': len(train_names),\n",
    "            'test_names': len(test_names),\n",
    "            'train_labels_0': train_labels_0,\n",
    "            'train_labels_1': train_labels_1,\n",
    "            'test_labels_0': test_labels_0,\n",
    "            'test_labels_1': test_labels_1,\n",
    "            'total_samples': len(train_names) + len(test_names)\n",
    "        }\n",
    "        \n",
    "        print(f\"{category}:\")\n",
    "        print(f\"  Train names: {len(train_names)}\")\n",
    "        print(f\"  Train labels - 0s: {train_labels_0}, 1s: {train_labels_1}\")\n",
    "        print(f\"  Test names: {len(test_names)}\")\n",
    "        print(f\"  Test labels - 0s: {test_labels_0}, 1s: {test_labels_1}\")\n",
    "        print(f\"  Total samples: {len(train_names) + len(test_names)}\")\n",
    "    \n",
    "    # Create summary table\n",
    "    df = pd.DataFrame(stats).T\n",
    "    print(f\"\\nSummary table:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Overall totals\n",
    "    print(f\"\\nOverall totals across filtered categories:\")\n",
    "    print(f\"Total train samples: {df['train_names'].sum()}\")\n",
    "    print(f\"Total test samples: {df['test_names'].sum()}\")\n",
    "    print(f\"Total train labels - 0s: {df['train_labels_0'].sum()}, 1s: {df['train_labels_1'].sum()}\")\n",
    "    print(f\"Total test labels - 0s: {df['test_labels_0'].sum()}, 1s: {df['test_labels_1'].sum()}\")\n",
    "    print(f\"Grand total samples: {df['total_samples'].sum()}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze each file separately\n",
    "all_stats = {}\n",
    "for file_path in LABEL_FILES:\n",
    "    stats = analyze_dataset_file(file_path)\n",
    "    if stats:\n",
    "        all_stats[file_path] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48cbdefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMBINED STATISTICS USING SUM_INDEXES\n",
      "============================================================\n",
      "\n",
      "--- Sum Group 1: Files [0, 2] ---\n",
      "Including: Dataset1/Labels/dataset_1_vul_two_one_names_labels.json\n",
      "Including: Dataset2/Labels/dataset2_train_test_names_labels.json\n",
      "\n",
      "Combined results for files: ['Dataset1/Labels/dataset_1_vul_two_one_names_labels.json', 'Dataset2/Labels/dataset2_train_test_names_labels.json']\n",
      "\n",
      "reentrancy-eth:\n",
      "  Total samples: 1273\n",
      "  Total 0s: 848\n",
      "  Total 1s: 425\n",
      "  Ratio (1s/total): 0.334\n",
      "\n",
      "Reentrancy:\n",
      "  Total samples: 63\n",
      "  Total 0s: 42\n",
      "  Total 1s: 21\n",
      "  Ratio (1s/total): 0.333\n",
      "\n",
      "==============================\n",
      "OVERALL TOTALS FOR GROUP 1:\n",
      "Total 0s across all categories: 890\n",
      "Total 1s across all categories: 446\n",
      "Grand total samples: 1336\n",
      "Overall ratio (1s/total): 0.334\n",
      "==============================\n",
      "\n",
      "--- Sum Group 2: Files [1, 2] ---\n",
      "Including: Dataset1/Labels/dataset_1_vul_five_one_names_labels.json\n",
      "Including: Dataset2/Labels/dataset2_train_test_names_labels.json\n",
      "\n",
      "Combined results for files: ['Dataset1/Labels/dataset_1_vul_five_one_names_labels.json', 'Dataset2/Labels/dataset2_train_test_names_labels.json']\n",
      "\n",
      "reentrancy-eth:\n",
      "  Total samples: 2548\n",
      "  Total 0s: 2123\n",
      "  Total 1s: 425\n",
      "  Ratio (1s/total): 0.167\n",
      "\n",
      "Reentrancy:\n",
      "  Total samples: 63\n",
      "  Total 0s: 42\n",
      "  Total 1s: 21\n",
      "  Ratio (1s/total): 0.333\n",
      "\n",
      "==============================\n",
      "OVERALL TOTALS FOR GROUP 2:\n",
      "Total 0s across all categories: 2165\n",
      "Total 1s across all categories: 446\n",
      "Grand total samples: 2611\n",
      "Overall ratio (1s/total): 0.171\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Combine statistics using SUM_INDEXES\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINED STATISTICS USING SUM_INDEXES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for idx, sum_group in enumerate(SUM_INDEXES):\n",
    "    print(f\"\\n--- Sum Group {idx + 1}: Files {sum_group} ---\")\n",
    "    \n",
    "    combined_stats = {}\n",
    "    valid_files = []\n",
    "    \n",
    "    # Collect stats from specified file indexes\n",
    "    for file_idx in sum_group:\n",
    "        if file_idx < len(LABEL_FILES):\n",
    "            file_path = LABEL_FILES[file_idx]\n",
    "            if file_path in all_stats:\n",
    "                valid_files.append(file_path)\n",
    "                print(f\"Including: {file_path}\")\n",
    "                \n",
    "                for category, stats in all_stats[file_path].items():\n",
    "                    if category not in combined_stats:\n",
    "                        combined_stats[category] = {\n",
    "                            'train_names': 0,\n",
    "                            'test_names': 0,\n",
    "                            'train_labels_0': 0,\n",
    "                            'train_labels_1': 0,\n",
    "                            'test_labels_0': 0,\n",
    "                            'test_labels_1': 0\n",
    "                        }\n",
    "                    \n",
    "                    # Sum up the statistics\n",
    "                    for key in combined_stats[category]:\n",
    "                        combined_stats[category][key] += stats[key]\n",
    "    \n",
    "    if not combined_stats:\n",
    "        print(\"No valid statistics found for this group.\")\n",
    "        continue\n",
    "    \n",
    "    # Display combined results\n",
    "    print(f\"\\nCombined results for files: {valid_files}\")\n",
    "    \n",
    "    total_0s = 0\n",
    "    total_1s = 0\n",
    "    \n",
    "    for category, stats in combined_stats.items():\n",
    "        category_0s = stats['train_labels_0'] + stats['test_labels_0']\n",
    "        category_1s = stats['train_labels_1'] + stats['test_labels_1']\n",
    "        \n",
    "        print(f\"\\n{category}:\")\n",
    "        print(f\"  Total samples: {stats['train_names'] + stats['test_names']}\")\n",
    "        print(f\"  Total 0s: {category_0s}\")\n",
    "        print(f\"  Total 1s: {category_1s}\")\n",
    "        print(f\"  Ratio (1s/total): {category_1s/(category_0s + category_1s):.3f}\")\n",
    "        \n",
    "        total_0s += category_0s\n",
    "        total_1s += category_1s\n",
    "    \n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"OVERALL TOTALS FOR GROUP {idx + 1}:\")\n",
    "    print(f\"Total 0s across all categories: {total_0s}\")\n",
    "    print(f\"Total 1s across all categories: {total_1s}\")\n",
    "    print(f\"Grand total samples: {total_0s + total_1s}\")\n",
    "    print(f\"Overall ratio (1s/total): {total_1s/(total_0s + total_1s):.3f}\")\n",
    "    print(f\"{'='*30}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
