{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse label structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reentrancy-eth:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "controlled-array-length:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "suicidal:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "controlled-delegatecall:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "arbitrary-send:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "tod:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "uninitialized-state:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "incorrect-equality:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "integer-overflow:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "unchecked-lowlevel:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "tx-origin:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "locked-ether:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "unchecked-send:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "boolean-cst:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "erc721-interface:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "erc20-interface:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "costly-loop:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "timestamp:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "block-other-parameters:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "calls-loop:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "low-level-calls:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "erc20-indexed:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "erc20-throw:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "hardcoded:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "array-instead-bytes:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "unused-state:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "costly-operations-loop:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "send-transfer:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "boolean-equal:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n",
      "external-function:\n",
      "    train_labels\n",
      "    train_names\n",
      "    test_labels\n",
      "    test_names\n"
     ]
    }
   ],
   "source": [
    "# This cell reads the JSON file and prints the first two levels of its structure.\n",
    "import json\n",
    "\n",
    "file_path = \"/workspaces/VulHunter/VulHunter/input2/dataset_1_vul_two_one_names_labels.json\"\n",
    "\n",
    "def print_two_level_structure(data, indent=0):\n",
    "    indent_str = \"    \" * indent\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            # Print the top-level key\n",
    "            print(f\"{indent_str}{key}:\")\n",
    "            # If its value is a dictionary, print its keys as subfields\n",
    "            if isinstance(value, dict):\n",
    "                for sub_key in value.keys():\n",
    "                    print(f\"{indent_str}    {sub_key}\")\n",
    "            # If its value is a list, try to show structure from first element if it's a dict\n",
    "            elif isinstance(value, list) and value:\n",
    "                print(f\"{indent_str}    [list]\")\n",
    "                first_elem = value[0]\n",
    "                if isinstance(first_elem, dict):\n",
    "                    for sub_key in first_elem.keys():\n",
    "                        print(f\"{indent_str}        {sub_key}\")\n",
    "            else:\n",
    "                print(f\"{indent_str}    [value]\")\n",
    "    else:\n",
    "        print(\"Data is not a dictionary at the top level.\")\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print_two_level_structure(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfield \"train_labels\" contains 1018 entries.\n",
      "Subfield \"train_names\" contains 1018 entries.\n",
      "Subfield \"test_labels\" contains 255 entries.\n",
      "Subfield \"test_names\" contains 255 entries.\n"
     ]
    }
   ],
   "source": [
    "# This cell analyzes the \"reentrancy-eth\" subfield of the JSON,\n",
    "# printing the number of entries in each of its subfields (assuming they are arrays).\n",
    "import json\n",
    "\n",
    "file_path = \"/workspaces/VulHunter/VulHunter/input2/dataset_1_vul_two_one_names_labels.json\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Ensure the \"reentrancy-eth\" key exists at the top level\n",
    "if \"reentrancy-eth\" not in data:\n",
    "    print('The key \"reentrancy-eth\" was not found in the JSON data.')\n",
    "else:\n",
    "    reentrancy_eth = data[\"reentrancy-eth\"]\n",
    "    if not isinstance(reentrancy_eth, dict):\n",
    "        print('The \"reentrancy-eth\" subfield is not a dictionary.')\n",
    "    else:\n",
    "        for subfield, value in reentrancy_eth.items():\n",
    "            if isinstance(value, list):\n",
    "                print(f'Subfield \"{subfield}\" contains {len(value)} entries.')\n",
    "            else:\n",
    "                print(f'Subfield \"{subfield}\" is not a list.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New JSON with reentrancy-eth subfield saved to: /workspaces/VulHunter/VulHunter/input2/dataset_1_vul_two_one_names_labels_reentrancy.json\n"
     ]
    }
   ],
   "source": [
    "# This cell reads the JSON file, extracts the \"reentrancy-eth\" subfield, \n",
    "# and writes it to a new JSON file with the suffix _reentrancy.\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "input_file = \"/workspaces/VulHunter/VulHunter/input2/dataset_1_vul_two_one_names_labels.json\"\n",
    "output_file = input_file.replace(\".json\", \"_reentrancy.json\")\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "if \"reentrancy-eth\" in data:\n",
    "    new_data = {\"reentrancy-eth\": data[\"reentrancy-eth\"]}\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(new_data, f, indent=4)\n",
    "    print(f'New JSON with reentrancy-eth subfield saved to: {output_file}')\n",
    "else:\n",
    "    print('The key \"reentrancy-eth\" was not found in the JSON data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered JSON saved to: /workspaces/VulHunter/VulHunter/input2/contract_bytecodes_list10_reentrancy.json\n"
     ]
    }
   ],
   "source": [
    "# This cell loads two JSON files:\n",
    "# keys.json: contains filtering keys in arrays \"test_names\" and \"train_names\" under the \"reentrancy_eth\" or \"reentrancy-eth\" subfield.\n",
    "# input.json: the JSON to be filtered.\n",
    "# It then filters input.json to only include keys present in the union of \"test_names\" and \"train_names\",\n",
    "# and writes the resulting JSON to a new file with the suffix \"_reentrancy.json\".\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Paths for the JSON files\n",
    "keys_file = \"/workspaces/VulHunter/VulHunter/input2/dataset_1_vul_two_one_names_labels.json\"\n",
    "input_file = \"/workspaces/VulHunter/VulHunter/input2/contract_bytecodes_list10.json\"\n",
    "output_file = input_file.replace(\".json\", \"_reentrancy.json\")\n",
    "\n",
    "# Load the keys JSON file\n",
    "with open(keys_file, \"r\") as f:\n",
    "    keys_data = json.load(f)\n",
    "\n",
    "# Try to get the filtering keys from \"reentrancy_eth\" or \"reentrancy-eth\"\n",
    "reentrancy_data = None\n",
    "if \"reentrancy_eth\" in keys_data and isinstance(keys_data[\"reentrancy_eth\"], dict):\n",
    "    reentrancy_data = keys_data[\"reentrancy_eth\"]\n",
    "elif \"reentrancy-eth\" in keys_data and isinstance(keys_data[\"reentrancy-eth\"], dict):\n",
    "    reentrancy_data = keys_data[\"reentrancy-eth\"]\n",
    "\n",
    "if not reentrancy_data:\n",
    "    print('No valid \"reentrancy_eth\" or \"reentrancy-eth\" subfield found in keys JSON.')\n",
    "else:\n",
    "    test_names = reentrancy_data.get(\"test_names\", [])\n",
    "    train_names = reentrancy_data.get(\"train_names\", [])\n",
    "    # Merge the two lists into a set for efficient lookup.\n",
    "    filter_keys = set(test_names + train_names)\n",
    "    \n",
    "    # Load the input JSON file to be filtered\n",
    "    with open(input_file, \"r\") as f:\n",
    "        input_data = json.load(f)\n",
    "\n",
    "    # Filter the input JSON: keep only keys that are in filter_keys\n",
    "    filtered_data = { key: value for key, value in input_data.items() if key in filter_keys }\n",
    "    \n",
    "    # Write the filtered data to the output JSON file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(filtered_data, f, indent=4)\n",
    "    \n",
    "    print(f\"Filtered JSON saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
